{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim import corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "\n",
    "text2 =  [\n",
    "    \"\"\"The government announced a new economic policy, Global markets reacted positively to the news, and Experts predict economic growth in the coming year, we first tokenize the text into words and create a Dictionary that assigns each word a unique ID.\"\"\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dictionary has: 35 tokens\n",
      "\n",
      "{'Dictionary': 0, 'Experts': 1, 'Global': 2, 'ID.': 3, 'The': 4, 'a': 5, 'and': 6, 'announced': 7, 'assigns': 8, 'coming': 9, 'create': 10, 'each': 11, 'economic': 12, 'first': 13, 'government': 14, 'growth': 15, 'in': 16, 'into': 17, 'markets': 18, 'new': 19, 'news,': 20, 'policy,': 21, 'positively': 22, 'predict': 23, 'reacted': 24, 'text': 25, 'that': 26, 'the': 27, 'to': 28, 'tokenize': 29, 'unique': 30, 'we': 31, 'word': 32, 'words': 33, 'year,': 34}\n",
      "Bag of Words :  [[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 3), (6, 2), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 2), (13, 1), (14, 1), (15, 1), (16, 1), (17, 1), (18, 1), (19, 1), (20, 1), (21, 1), (22, 1), (23, 1), (24, 1), (25, 1), (26, 1), (27, 3), (28, 1), (29, 1), (30, 1), (31, 1), (32, 1), (33, 1), (34, 1)]]\n"
     ]
    }
   ],
   "source": [
    "tokens2 = [[item for item in line.split()] for line in text2]\n",
    "g_dict2 = corpora.Dictionary(tokens2)\n",
    "\n",
    "print(\"The dictionary has: \" + str(len(g_dict2)) + \" tokens\\n\")\n",
    "print(g_dict2.token2id)\n",
    "\n",
    "g_bow2 = [g_dict2.doc2bow(token, allow_update=True) for token in tokens2]\n",
    "print(\"Bag of Words : \", g_bow2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dictionary : \n",
      "[['and', 2], ['announced', 1], ['assigns', 1], ['coming', 1], ['create', 1], ['dictionary', 1], ['each', 1], ['economic', 2], ['experts', 1], ['first', 1], ['global', 1], ['government', 1], ['growth', 1], ['id', 1], ['in', 1], ['into', 1], ['markets', 1], ['new', 1], ['news', 1], ['policy', 1], ['positively', 1], ['predict', 1], ['reacted', 1], ['text', 1], ['that', 1], ['the', 4], ['to', 1], ['tokenize', 1], ['unique', 1], ['we', 1], ['word', 1], ['words', 1], ['year', 1]]\n"
     ]
    }
   ],
   "source": [
    "text3 =  [\n",
    "    \"\"\"The government announced a new economic policy, Global markets reacted positively to the news, and Experts predict economic growth in the coming year, we first tokenize the text into words and create a Dictionary that assigns each word a unique ID.\"\"\"]\n",
    "\n",
    "g_dict3 = corpora.Dictionary([simple_preprocess(line) for line in text3])\n",
    "g_bow3 = [g_dict3.doc2bow(simple_preprocess(line)) for line in text3]\n",
    "\n",
    "print(\"\\nDictionary : \")\n",
    "for item in g_bow3:\n",
    "    print([[g_dict3[id], freq] for id, freq in item])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
